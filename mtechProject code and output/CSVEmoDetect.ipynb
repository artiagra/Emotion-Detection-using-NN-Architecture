{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "---------------------------------------\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "SeqLength = 42\n",
    "counter = 0\n",
    "for p in wordsList:\n",
    "    counter = counter+1\n",
    "    if counter >= SeqLength:                \n",
    "        break\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.039495  ,  1.5316    , -0.39991999, -0.20091   ,  1.37839997,\n",
       "        0.23264   ,  0.40810999,  0.09424   ,  0.80492997,  1.18900001,\n",
       "        0.37090001,  0.29229999,  0.051458  , -0.91470999,  0.79913002,\n",
       "        0.031613  ,  0.23425999, -0.078071  ,  0.55264997, -0.094033  ,\n",
       "       -0.067781  ,  0.94492   ,  0.13196   , -0.2352    ,  1.61380005,\n",
       "       -0.31953001, -1.30379999, -0.33394   ,  1.0244    ,  0.12196   ,\n",
       "        1.58580005,  1.08249998, -0.15639   , -0.38266999, -0.76346999,\n",
       "       -0.49954   , -0.52539998, -0.33105999,  0.29729   , -0.17441   ,\n",
       "       -0.076043  , -0.83092999, -0.47857001, -0.029247  , -0.26328999,\n",
       "       -0.30849999,  0.15287   , -0.30546999,  0.15899   , -0.30671   ], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joyIndex = wordsList.index('happiness')\n",
    "print(joyIndex)\n",
    "wordVectors[joyIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[ 9811  1655  3946 13866 18741  2661  5876     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "inputSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "inputSentence[0] = wordsList.index(\"happiness\")\n",
    "inputSentence[1] = wordsList.index(\"fear\")\n",
    "inputSentence[2] = wordsList.index(\"anger\")\n",
    "inputSentence[3] = wordsList.index(\"sadness\")\n",
    "inputSentence[4] = wordsList.index(\"disgust\")\n",
    "inputSentence[5] = wordsList.index(\"surprise\")\n",
    "inputSentence[6] = wordsList.index(\"neutral\")\n",
    "#inputSentence[7],inputSentence[8] and inputSentence[9] are going to be 0\n",
    "print(inputSentence.shape)\n",
    "print(inputSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.039495    1.5316     -0.39991999 -0.20091     1.37839997  0.23264\n",
      "   0.40810999  0.09424     0.80492997  1.18900001  0.37090001  0.29229999\n",
      "   0.051458   -0.91470999  0.79913002  0.031613    0.23425999 -0.078071\n",
      "   0.55264997 -0.094033   -0.067781    0.94492     0.13196    -0.2352\n",
      "   1.61380005 -0.31953001 -1.30379999 -0.33394     1.0244      0.12196\n",
      "   1.58580005  1.08249998 -0.15639    -0.38266999 -0.76346999 -0.49954\n",
      "  -0.52539998 -0.33105999  0.29729    -0.17441    -0.076043   -0.83092999\n",
      "  -0.47857001 -0.029247   -0.26328999 -0.30849999  0.15287    -0.30546999\n",
      "   0.15899    -0.30671   ]\n",
      " [ 0.53661001 -0.33871999  0.28771999 -0.72583997 -0.041209    0.28498\n",
      "   0.21664999  0.62408    -0.1204      0.41135001  0.10111    -0.11545\n",
      "  -0.15651999 -0.39265001  0.66285998  0.71562999  0.42140001 -0.37041\n",
      "  -0.081016   -0.29010001 -0.28406999  0.30706999  0.035974    0.32001999\n",
      "   0.45456001 -2.08299994 -0.65890002 -0.081918    1.0431      0.50839001\n",
      "   2.54329991  0.81831998 -0.11508    -1.14709997 -1.04219997 -0.22972\n",
      "  -0.68159002 -1.36329997  0.063994   -0.27114999 -0.41005999  0.090468\n",
      "   0.19801     0.486       0.84081     0.38655001 -0.40763     0.20565\n",
      "  -0.1169     -0.55730999]\n",
      " [-0.044806    0.24917001  0.088818   -0.79820001  0.15030999  0.6785\n",
      "   0.83495998  0.86423999 -0.71302003  0.75296003 -0.31584999 -0.29640001\n",
      "  -0.12553    -0.73859     0.15350001  0.18059    -0.080169    0.0029328\n",
      "  -0.14162999 -0.56985003  0.38888001  0.63090003  0.038375   -0.32776999\n",
      "   0.72166002 -1.96990001  0.081391    0.55689001  0.73193002  0.83257997\n",
      "   2.03620005  1.1322      0.31966999 -1.13269997 -1.38129997 -0.30715999\n",
      "  -0.77534997 -1.54390001  0.02619    -0.067238    0.018815    0.47666001\n",
      "  -0.80436999  0.13336     1.05040002  0.28345001 -0.54026002  0.39379999\n",
      "  -0.30180001 -0.91219002]\n",
      " [ 0.38248     1.31659997 -0.67795998 -0.23382001  0.92054999  0.39704999\n",
      "   1.09539998  1.34749997 -0.33678001  0.71332997  0.055274    0.25823\n",
      "  -0.14289001 -0.72494     0.60271001  0.048186   -0.55067003 -0.0056619\n",
      "  -0.015116   -0.67900002 -0.52648997  1.45720005  0.44992    -0.70761001\n",
      "   1.56099999 -0.41428    -1.17980003  0.98562998  1.00450003  0.80479997\n",
      "   1.11819994  1.39090002  0.70073003 -0.49184999 -0.96939999 -0.32769001\n",
      "  -0.34097999 -1.39590001  0.67482001  0.13913999  0.18353     0.25068\n",
      "  -0.92971998 -0.28589001  0.27042001  0.84941    -0.44641     0.50313997\n",
      "  -0.37851    -0.65622997]\n",
      " [-0.55734998  0.088292   -0.34505001 -0.51239997  0.33486     0.50617999\n",
      "   0.90091002  0.87638003 -0.55048001  0.31889999 -0.14744    -0.022987\n",
      "  -0.32802001 -0.22225     0.023042   -0.26524001 -0.53355002  0.013756\n",
      "  -0.098625   -0.88335001 -0.018759    0.90394002  0.2552     -0.48816001\n",
      "   0.85610998 -1.19369996 -0.19683     1.0503      0.40810001  0.23352\n",
      "   0.52847999  1.16980004  0.28227001 -0.8829     -1.51820004 -0.15557\n",
      "  -0.37391999 -1.01230001  0.38461    -0.21142     0.36866999  0.26028001\n",
      "  -0.98470002  0.6882      0.38736999  0.090635   -0.22709     0.25281\n",
      "   0.23433    -1.01139998]\n",
      " [ 0.43138     0.25560001 -0.0054598   0.26719999  0.41846001 -0.30282\n",
      "  -0.42897999  1.25539994 -0.37419     0.42207    -0.38163999 -0.45100999\n",
      "  -0.24843    -0.18889     0.85611999 -0.15808     0.13082001 -0.77788001\n",
      "  -1.02470005 -0.47486001  0.054011   -0.1516     -0.18829    -0.36844999\n",
      "   0.44512001 -1.57099998 -0.55777001  0.21816     0.26315001  0.18358999\n",
      "   2.08940005  0.68848997 -0.16336    -0.1216      0.038419   -0.30199999\n",
      "   0.06687     0.21847001 -0.47898999 -1.17060006  0.093452    0.28611001\n",
      "  -0.55597001 -0.65429002  0.66781998  0.04971    -0.0052173   0.70060003\n",
      "   0.32464999  0.24523   ]\n",
      " [ 0.10193    -0.31174999 -0.32207    -0.069121    0.83464003 -0.19136\n",
      "   0.61142999 -0.048183   -0.56900001 -0.31073999  1.01090002  0.41018\n",
      "   0.07679     0.53938001 -0.35247001  1.08679998  0.87826997 -0.15841\n",
      "  -0.28286999 -0.71635002 -0.050837   -0.024865    0.73021001  0.60965002\n",
      "  -0.74800003 -0.63331002  0.59424001  0.89076     0.21573     0.68681002\n",
      "   2.04699993 -0.46432999 -0.081564   -0.84878999 -0.21514    -0.77162999\n",
      "  -0.18683    -0.16663    -0.51516998 -0.67672998  0.46656999 -0.33408999\n",
      "   0.72180998  0.15685999 -0.52403998 -0.22545999 -0.23131     0.32637\n",
      "   0.30858999  0.54118001]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,inputSentence).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# file = pd.read_csv('iseardataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file['text'][1606]\n",
    "# file['label'][1606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textList = file['text']\n",
    "# textList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numWords = []\n",
    "# count=0\n",
    "# for pf in textList:\n",
    "#     counter = len(pf.split())\n",
    "#     numWords.append(counter)\n",
    "#     if(counter > 180):\n",
    "#         count=count+1\n",
    "    \n",
    "# print('files read finished')\n",
    "\n",
    "# numFiles = len(numWords)\n",
    "# print('The total number of files is', numFiles)\n",
    "# print('The total number of words in the files is', sum(numWords))\n",
    "# print('The average number of words in the files is', sum(numWords)/len(numWords))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file1 = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledColumn = file1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = labelledColumn.replace(\"worry\",\"sadness\")\n",
    "ll = ll.replace(\"love\",\"happiness\")\n",
    "ll = ll.replace(\"fun\",\"happiness\")\n",
    "ll = ll.replace(\"enthusiasm\",\"happiness\")\n",
    "ll = ll.replace(\"empty\",\"sadness\")\n",
    "ll = ll.replace(\"boredom\",\"neutral\")\n",
    "ll = ll.replace(\"relief\",\"happiness\")\n",
    "ll = ll.replace(\"hate\",\"anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sadness', 'happiness', 'neutral', 'fear', 'surprise', 'anger']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWord1 = []\n",
    "for word in ll:\n",
    "    if word not in uniqueWord1:\n",
    "        uniqueWord1.append(word)\n",
    "        \n",
    "uniqueWord1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14043, 13110, 8826, 401, 2187, 1433]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter1 = []\n",
    "for word in uniqueWord1:\n",
    "    count = 0\n",
    "    for word1 in ll:\n",
    "        if word == word1:\n",
    "            count=count+1\n",
    "    counter1.append(count)\n",
    "\n",
    "counter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList1 = file1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files read finished\n",
      "The total number of files is 40000\n",
      "The total number of words in the files is 528675\n",
      "The average number of words in the files is 13.216875\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "numWords1 = []\n",
    "count1=0\n",
    "for pf in textList1:\n",
    "    counter1 = len(pf.split())\n",
    "    numWords1.append(counter1)\n",
    "    if(counter1 > 40):\n",
    "        count1=count1+1\n",
    "    \n",
    "print('files read finished')\n",
    "\n",
    "numFiles1 = len(numWords1)\n",
    "print('The total number of files is', numFiles1)\n",
    "print('The total number of words in the files is', sum(numWords1))\n",
    "print('The average number of words in the files is', sum(numWords1)/len(numWords1))\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"\\n\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "# pf = textList[0]\n",
    "# indexCounter = 0\n",
    "# cleanedLine = cleanSentences(pf)\n",
    "# split = cleanedLine.split()\n",
    "# for word in split:\n",
    "#     try:\n",
    "#         firstFile[indexCounter] = wordsList.index(word)\n",
    "#     except ValueError:\n",
    "#         firstFile[indexCounter] = 399999 #Vector for unknown words\n",
    "#     indexCounter = indexCounter + 1\n",
    "# firstFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelPrediction = [\"happiness\",\"fear\",\"anger\",\"sadness\",\"surprise\",\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numFiles = numFiles + numFiles1\n",
    "ids = np.zeros((numFiles1, maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "# for pf in textList:\n",
    "#     indexCounter = 0\n",
    "#     cleanedLine = cleanSentences(pf)\n",
    "#     split = cleanedLine.split()\n",
    "#     for word in split:\n",
    "#         try:\n",
    "#             ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#         except ValueError:\n",
    "#             ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#         indexCounter = indexCounter + 1\n",
    "#         if indexCounter >= maxSeqLength:\n",
    "#             break\n",
    "#     fileCounter = fileCounter + 1 \n",
    "    \n",
    "# for pf in textList1:\n",
    "#     indexCounter = 0\n",
    "#     cleanedLine = cleanSentences(pf)\n",
    "#     split = cleanedLine.split()\n",
    "#     for word in split:\n",
    "#         try:\n",
    "#             ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#         except ValueError:\n",
    "#             ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#         indexCounter = indexCounter + 1\n",
    "#         if indexCounter >= maxSeqLength:\n",
    "#             break\n",
    "#     fileCounter = fileCounter + 1 \n",
    "# np.save('idsMatrixFile1', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([399999, 399999,    738,  93325,     81,    242,      4,  22152,\n",
       "         1832,    192,  34140,  93325,    117,    192,   1095,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.load('idsMatrixFile1.npy')\n",
    "ids[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[399999 399999    738  93325     81    242      4  22152   1832    192\n",
      "  34140  93325    117    192   1095      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends\n"
     ]
    }
   ],
   "source": [
    "print(ids[5])\n",
    "print(textList1[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 40)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27053\n",
      "happiness\n",
      "Por Favor!!! Only need FIVE more!  http://tinyurl.com/dzcpg3\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "1033\n",
      "happiness\n",
      "To all my friends: Im deeply sorry i'm moving, i will miss u all so very very much!\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "20169\n",
      "neutral\n",
      "@TessMorris fine! Going to do my big walk today 20 or so miles\n",
      "5876\n",
      "(40,)\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "21083\n",
      "happiness\n",
      "@Broooooke_ listen to FTSK  they stop my bordum  haha how was your day? finished crying about Harold? ha xx\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "16731\n",
      "neutral\n",
      "Back in Spain\n",
      "5876\n",
      "(40,)\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "15191\n",
      "sadness\n",
      "@lovexoL what happened to your phone\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "4532\n",
      "sadness\n",
      "@JonathanRKnight welcome back! I'm stuck in jury duty today.\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "7993\n",
      "sadness\n",
      "I need to sit  my insides hurt ughhh\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "25441\n",
      "neutral\n",
      "@goebicyu Thank you very much for the Follow. I have re-followed you also\n",
      "5876\n",
      "(40,)\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "38767\n",
      "happiness\n",
      "Wake up x.x But tired. On this moment i listing some music for make me happy and let me wake up\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "1041\n",
      "fear\n",
      "gonna get off to try and catch some Z's, no more high school after tomorrow! which really sucks  i wish i didn.. http://tinyurl.com/lk9ag8\n",
      "1655\n",
      "(40,)\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "5475\n",
      "happiness\n",
      "@clovisdied *hugs* me too.\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "16905\n",
      "sadness\n",
      "@AndreaKoeln hmm, okayy, im really sorry to hear about it  why do you thikn she would have done that? :S\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "24847\n",
      "neutral\n",
      "Loves her david soooooo much &lt;3\n",
      "5876\n",
      "(40,)\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "19571\n",
      "sadness\n",
      "@ravels http://twitpic.com/67fs9 - I miss hearing you guys.  You will all be missed out here.\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "37164\n",
      "happiness\n",
      "@dekrazee1 You are doing the right thing though.  A fridge is where vegetables go to die\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "30653\n",
      "neutral\n",
      "Happy mother's day, mama. You're the most amazing person I've ever known and I'm so proud to be born as your daughter\n",
      "5876\n",
      "(40,)\n",
      "[0, 0, 0, 0, 0, 1]\n",
      "34536\n",
      "sadness\n",
      "@Karen230683 @amysav83 remember and drink plenty of fluids! and no buwieser dose not count!\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "19499\n",
      "sadness\n",
      "is SOOOOO hungry right now! Should've eaten before this wedding.\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "39408\n",
      "happiness\n",
      "Happy Mother's Day, Moms!!! You are wonderful!! Have a great day\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "10496\n",
      "anger\n",
      "I really don't like this weather\n",
      "3946\n",
      "(40,)\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "5904\n",
      "happiness\n",
      "@dreamobscene I know how you feel  Have a lovely relaxing weekend!\n",
      "9811\n",
      "(40,)\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "18\n",
      "fear\n",
      "@PerezHilton lady gaga tweeted about not being impressed by her video leaking just so you know\n",
      "1655\n",
      "(40,)\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "15241\n",
      "sadness\n",
      "is missing her best friend  commme back kayla, going out in a little while\n",
      "13866\n",
      "(40,)\n",
      "[0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "labels = []\n",
    "batchSize =24\n",
    "arr = np.zeros([batchSize, maxSeqLength])\n",
    "for i in range(batchSize):\n",
    "     num = randint(1,39999)\n",
    "     print(num)\n",
    "     labeltxt = ll[num]\n",
    "     print(labeltxt)\n",
    "     labelemo = textList1[num]\n",
    "     print(labelemo)\n",
    "     labelindex = wordsList.index(labeltxt)\n",
    "     print(labelindex)\n",
    "     arr[i] = ids[num-1:num]\n",
    "     print(arr[i].shape)\n",
    "     if labeltxt==\"happiness\":\n",
    "        labels.append([1,0,0,0,0,0])\n",
    "     elif labeltxt==\"fear\":\n",
    "        labels.append([0,1,0,0,0,0])\n",
    "     elif labeltxt==\"anger\":\n",
    "        labels.append([0,0,1,0,0,0])\n",
    "     elif labeltxt==\"sadness\":\n",
    "        labels.append([0,0,0,1,0,0])\n",
    "     elif labeltxt==\"surprise\":\n",
    "        labels.append([0,0,0,0,1,0])\n",
    "     elif labeltxt==\"neutral\":\n",
    "        labels.append([0,0,0,0,0,1])\n",
    "     print(labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,29999)\n",
    "        labeltxt = ll[num]\n",
    "        labelindex = wordsList.index(labeltxt)\n",
    "        arr[i] = ids[num-1:num]\n",
    "        if labeltxt==\"happiness\":\n",
    "            labels.append([1,0,0,0,0,0])\n",
    "        elif labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0])\n",
    "        elif labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0])\n",
    "        elif labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0])\n",
    "        elif labeltxt==\"surprise\":\n",
    "            labels.append([0,0,0,0,1,0])\n",
    "        elif labeltxt==\"neutral\":\n",
    "            labels.append([0,0,0,0,0,1])\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(30000,39999)\n",
    "        #labeltxt = file['label'][num]\n",
    "        labeltxt = ll[num]\n",
    "        labelindex = wordsList.index(labeltxt)\n",
    "        arr[i] = ids[num-1:num]\n",
    "        if labeltxt==\"happiness\":\n",
    "            labels.append([1,0,0,0,0,0])\n",
    "        elif labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0])\n",
    "        elif labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0])\n",
    "        elif labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0])\n",
    "        elif labeltxt==\"surprise\":\n",
    "            labels.append([0,0,0,0,1,0])\n",
    "        elif labeltxt==\"neutral\":\n",
    "            labels.append([0,0,0,0,0,1])\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 6\n",
    "iterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(24), Dimension(40), Dimension(50)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#    #Next Batch of reviews\n",
    "#    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "#    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "#    #Write summary to Tensorboard\n",
    "#    if (i % 50 == 0):\n",
    "#        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "#        writer.add_summary(summary, i)\n",
    "\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"file1Models/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from file1Models\\pretrained_lstm.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('file1Models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 25.0\n",
      "Accuracy for this batch: 29.1666656733\n",
      "Accuracy for this batch: 54.1666686535\n",
      "Accuracy for this batch: 29.1666656733\n",
      "Accuracy for this batch: 58.3333313465\n",
      "Accuracy for this batch: 25.0\n",
      "Accuracy for this batch: 33.3333343267\n",
      "Accuracy for this batch: 33.3333343267\n",
      "Accuracy for this batch: 41.6666656733\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
    "    cleanedSentence = cleanSentences(sentence)\n",
    "    split = cleanedSentence.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        try:\n",
    "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unknown words\n",
    "    return sentenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"so sad\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "\n",
    "# print(\"happiness = \",predictedSentiment[0])\n",
    "# print(\"fear=\",predictedSentiment[1])\n",
    "# print(\"anger=\",predictedSentiment[2])\n",
    "# print(\"sadness=\",predictedSentiment[3])\n",
    "# print(\"surprise=\",predictedSentiment[4])\n",
    "# print(\"neutral=\",predictedSentiment[5])\n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(predictedSentiment), key=operator.itemgetter(1))\n",
    "\n",
    "labelPrediction[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"i hate you\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "\n",
    "# print(\"happiness = \",predictedSentiment[0])\n",
    "# print(\"fear=\",predictedSentiment[1])\n",
    "# print(\"anger=\",predictedSentiment[2])\n",
    "# print(\"sadness=\",predictedSentiment[3])\n",
    "# print(\"surprise=\",predictedSentiment[4])\n",
    "# print(\"neutral=\",predictedSentiment[5])\n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(predictedSentiment), key=operator.itemgetter(1))\n",
    "\n",
    "labelPrediction[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
