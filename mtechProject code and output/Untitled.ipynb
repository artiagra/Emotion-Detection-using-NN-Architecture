{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "---------------------------------------\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "SeqLength = 42\n",
    "counter = 0\n",
    "for p in wordsList:\n",
    "    counter = counter+1\n",
    "    if counter >= SeqLength:                \n",
    "        break\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[ 9811  1655  3946 13866 18741    57   805     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "inputSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "inputSentence[0] = wordsList.index(\"happiness\")\n",
    "inputSentence[1] = wordsList.index(\"fear\")\n",
    "inputSentence[2] = wordsList.index(\"anger\")\n",
    "inputSentence[3] = wordsList.index(\"sadness\")\n",
    "inputSentence[4] = wordsList.index(\"disgust\")\n",
    "inputSentence[5] = wordsList.index(\"'\")\n",
    "inputSentence[6] = wordsList.index(\"!\")\n",
    "#inputSentence[7],inputSentence[8] and inputSentence[9] are going to be 0\n",
    "print(inputSentence.shape)\n",
    "print(inputSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.039495    1.5316     -0.39991999 -0.20091     1.37839997  0.23264\n",
      "   0.40810999  0.09424     0.80492997  1.18900001  0.37090001  0.29229999\n",
      "   0.051458   -0.91470999  0.79913002  0.031613    0.23425999 -0.078071\n",
      "   0.55264997 -0.094033   -0.067781    0.94492     0.13196    -0.2352\n",
      "   1.61380005 -0.31953001 -1.30379999 -0.33394     1.0244      0.12196\n",
      "   1.58580005  1.08249998 -0.15639    -0.38266999 -0.76346999 -0.49954\n",
      "  -0.52539998 -0.33105999  0.29729    -0.17441    -0.076043   -0.83092999\n",
      "  -0.47857001 -0.029247   -0.26328999 -0.30849999  0.15287    -0.30546999\n",
      "   0.15899    -0.30671   ]\n",
      " [ 0.53661001 -0.33871999  0.28771999 -0.72583997 -0.041209    0.28498\n",
      "   0.21664999  0.62408    -0.1204      0.41135001  0.10111    -0.11545\n",
      "  -0.15651999 -0.39265001  0.66285998  0.71562999  0.42140001 -0.37041\n",
      "  -0.081016   -0.29010001 -0.28406999  0.30706999  0.035974    0.32001999\n",
      "   0.45456001 -2.08299994 -0.65890002 -0.081918    1.0431      0.50839001\n",
      "   2.54329991  0.81831998 -0.11508    -1.14709997 -1.04219997 -0.22972\n",
      "  -0.68159002 -1.36329997  0.063994   -0.27114999 -0.41005999  0.090468\n",
      "   0.19801     0.486       0.84081     0.38655001 -0.40763     0.20565\n",
      "  -0.1169     -0.55730999]\n",
      " [-0.044806    0.24917001  0.088818   -0.79820001  0.15030999  0.6785\n",
      "   0.83495998  0.86423999 -0.71302003  0.75296003 -0.31584999 -0.29640001\n",
      "  -0.12553    -0.73859     0.15350001  0.18059    -0.080169    0.0029328\n",
      "  -0.14162999 -0.56985003  0.38888001  0.63090003  0.038375   -0.32776999\n",
      "   0.72166002 -1.96990001  0.081391    0.55689001  0.73193002  0.83257997\n",
      "   2.03620005  1.1322      0.31966999 -1.13269997 -1.38129997 -0.30715999\n",
      "  -0.77534997 -1.54390001  0.02619    -0.067238    0.018815    0.47666001\n",
      "  -0.80436999  0.13336     1.05040002  0.28345001 -0.54026002  0.39379999\n",
      "  -0.30180001 -0.91219002]\n",
      " [ 0.38248     1.31659997 -0.67795998 -0.23382001  0.92054999  0.39704999\n",
      "   1.09539998  1.34749997 -0.33678001  0.71332997  0.055274    0.25823\n",
      "  -0.14289001 -0.72494     0.60271001  0.048186   -0.55067003 -0.0056619\n",
      "  -0.015116   -0.67900002 -0.52648997  1.45720005  0.44992    -0.70761001\n",
      "   1.56099999 -0.41428    -1.17980003  0.98562998  1.00450003  0.80479997\n",
      "   1.11819994  1.39090002  0.70073003 -0.49184999 -0.96939999 -0.32769001\n",
      "  -0.34097999 -1.39590001  0.67482001  0.13913999  0.18353     0.25068\n",
      "  -0.92971998 -0.28589001  0.27042001  0.84941    -0.44641     0.50313997\n",
      "  -0.37851    -0.65622997]\n",
      " [-0.55734998  0.088292   -0.34505001 -0.51239997  0.33486     0.50617999\n",
      "   0.90091002  0.87638003 -0.55048001  0.31889999 -0.14744    -0.022987\n",
      "  -0.32802001 -0.22225     0.023042   -0.26524001 -0.53355002  0.013756\n",
      "  -0.098625   -0.88335001 -0.018759    0.90394002  0.2552     -0.48816001\n",
      "   0.85610998 -1.19369996 -0.19683     1.0503      0.40810001  0.23352\n",
      "   0.52847999  1.16980004  0.28227001 -0.8829     -1.51820004 -0.15557\n",
      "  -0.37391999 -1.01230001  0.38461    -0.21142     0.36866999  0.26028001\n",
      "  -0.98470002  0.6882      0.38736999  0.090635   -0.22709     0.25281\n",
      "   0.23433    -1.01139998]\n",
      " [ 0.43138     0.25560001 -0.0054598   0.26719999  0.41846001 -0.30282\n",
      "  -0.42897999  1.25539994 -0.37419     0.42207    -0.38163999 -0.45100999\n",
      "  -0.24843    -0.18889     0.85611999 -0.15808     0.13082001 -0.77788001\n",
      "  -1.02470005 -0.47486001  0.054011   -0.1516     -0.18829    -0.36844999\n",
      "   0.44512001 -1.57099998 -0.55777001  0.21816     0.26315001  0.18358999\n",
      "   2.08940005  0.68848997 -0.16336    -0.1216      0.038419   -0.30199999\n",
      "   0.06687     0.21847001 -0.47898999 -1.17060006  0.093452    0.28611001\n",
      "  -0.55597001 -0.65429002  0.66781998  0.04971    -0.0052173   0.70060003\n",
      "   0.32464999  0.24523   ]\n",
      " [ 0.10193    -0.31174999 -0.32207    -0.069121    0.83464003 -0.19136\n",
      "   0.61142999 -0.048183   -0.56900001 -0.31073999  1.01090002  0.41018\n",
      "   0.07679     0.53938001 -0.35247001  1.08679998  0.87826997 -0.15841\n",
      "  -0.28286999 -0.71635002 -0.050837   -0.024865    0.73021001  0.60965002\n",
      "  -0.74800003 -0.63331002  0.59424001  0.89076     0.21573     0.68681002\n",
      "   2.04699993 -0.46432999 -0.081564   -0.84878999 -0.21514    -0.77162999\n",
      "  -0.18683    -0.16663    -0.51516998 -0.67672998  0.46656999 -0.33408999\n",
      "   0.72180998  0.15685999 -0.52403998 -0.22545999 -0.23131     0.32637\n",
      "   0.30858999  0.54118001]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,inputSentence).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file1 = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledColumn = file1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = labelledColumn.replace(\"worry\",\"sadness\")\n",
    "ll = ll.replace(\"love\",\"happiness\")\n",
    "ll = ll.replace(\"fun\",\"happiness\")\n",
    "ll = ll.replace(\"enthusiasm\",\"happiness\")\n",
    "ll = ll.replace(\"empty\",\"sadness\")\n",
    "ll = ll.replace(\"boredom\",\"neutral\")\n",
    "ll = ll.replace(\"relief\",\"happiness\")\n",
    "ll = ll.replace(\"hate\",\"anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList1 = file1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"\\n\", \" \")\n",
    "    return re.sub(strip_special_chars, \" \", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanedText = []\n",
    "for p in textList1:\n",
    "    cleanedLine = cleanSentences(p)\n",
    "    CleanedText.append(cleanedLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = []\n",
    "for w in CleanedText:\n",
    "    splitedSentence = w.split()\n",
    "    filtering_sentence=[]\n",
    "    for s in splitedSentence:\n",
    "        if s not in stop_words:\n",
    "            filtering_sentence.append(s)\n",
    "    filtered_sentence.append(filtering_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiffanylue',\n",
       " 'know',\n",
       " 'listenin',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'earlier',\n",
       " 'started',\n",
       " 'freakin',\n",
       " 'part']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files read finished\n",
      "The total number of files is 40000\n",
      "The total number of words in the files is 315471\n",
      "The average number of words in the files is 7.886775\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "numWords1 = []\n",
    "count1=0\n",
    "for pf in filtered_sentence:\n",
    "    counter1 = len(pf)\n",
    "    numWords1.append(counter1)\n",
    "    if(counter1 > 30):\n",
    "        count1=count1+1\n",
    "    \n",
    "print('files read finished')\n",
    "\n",
    "numFiles1 = len(numWords1)\n",
    "print('The total number of files is', numFiles1)\n",
    "print('The total number of words in the files is', sum(numWords1))\n",
    "print('The average number of words in the files is', sum(numWords1)/len(numWords1))\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelPrediction = [\"happiness\",\"fear\",\"anger\",\"sadness\",\"surprise\",\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.zeros((numFiles1, maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for pf in filtered_sentence:\n",
    "    indexCounter = 0\n",
    "    for word in pf:\n",
    "        try:\n",
    "            ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "np.save('Data/idsMatrix1', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.load('Data/idsMatrix1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,29999)\n",
    "        labeltxt = ll[num]\n",
    "        labelindex = wordsList.index(labeltxt)\n",
    "        arr[i] = ids[num-1:num]\n",
    "        if labeltxt==\"happiness\":\n",
    "            labels.append([1,0,0,0,0,0])\n",
    "        elif labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0])\n",
    "        elif labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0])\n",
    "        elif labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0])\n",
    "        elif labeltxt==\"surprise\":\n",
    "            labels.append([0,0,0,0,1,0])\n",
    "        elif labeltxt==\"neutral\":\n",
    "            labels.append([0,0,0,0,0,1])\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(30000,39999)\n",
    "        #labeltxt = file['label'][num]\n",
    "        labeltxt = ll[num]\n",
    "        labelindex = wordsList.index(labeltxt)\n",
    "        arr[i] = ids[num-1:num]\n",
    "        if labeltxt==\"happiness\":\n",
    "            labels.append([1,0,0,0,0,0])\n",
    "        elif labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0])\n",
    "        elif labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0])\n",
    "        elif labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0])\n",
    "        elif labeltxt==\"surprise\":\n",
    "            labels.append([0,0,0,0,1,0])\n",
    "        elif labeltxt==\"neutral\":\n",
    "            labels.append([0,0,0,0,0,1])\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 6\n",
    "iterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(24), Dimension(40), Dimension(50)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to file1FilteredModels/pretrained_lstm.ckpt-10000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-20000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-30000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-40000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-50000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-60000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-70000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-80000\n",
      "saved to file1FilteredModels/pretrained_lstm.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#    #Next Batch of reviews\n",
    "#    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "#    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "#    #Write summary to Tensorboard\n",
    "#    if (i % 50 == 0):\n",
    "#        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "#        writer.add_summary(summary, i)\n",
    "\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"file1FilteredModels/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from file1FilteredModels\\pretrained_lstm.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('file1FilteredModels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 41.6666656733\n",
      "Accuracy for this batch: 25.0\n",
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 37.5\n",
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 25.0\n",
      "Accuracy for this batch: 16.6666671634\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 33.3333343267\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
    "    cleanedSentence = cleanSentences(sentence)\n",
    "    split = cleanedSentence.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        try:\n",
    "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unknown words\n",
    "    return sentenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"freak\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiness'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "\n",
    "# print(\"happiness = \",predictedSentiment[0])\n",
    "# print(\"fear=\",predictedSentiment[1])\n",
    "# print(\"anger=\",predictedSentiment[2])\n",
    "# print(\"sadness=\",predictedSentiment[3])\n",
    "# print(\"surprise=\",predictedSentiment[4])\n",
    "# print(\"neutral=\",predictedSentiment[5])\n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(predictedSentiment), key=operator.itemgetter(1))\n",
    "\n",
    "labelPrediction[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
