{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "---------------------------------------\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[ 9811  1655  3946 13866 18741  2661  5876     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "inputSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "inputSentence[0] = wordsList.index(\"happiness\")\n",
    "inputSentence[1] = wordsList.index(\"fear\")\n",
    "inputSentence[2] = wordsList.index(\"anger\")\n",
    "inputSentence[3] = wordsList.index(\"sadness\")\n",
    "inputSentence[4] = wordsList.index(\"disgust\")\n",
    "inputSentence[5] = wordsList.index(\"surprise\")\n",
    "inputSentence[6] = wordsList.index(\"neutral\")\n",
    "#inputSentence[7],inputSentence[8] and inputSentence[9] are going to be 0\n",
    "print(inputSentence.shape)\n",
    "print(inputSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.039495   1.5316    -0.39992   -0.20091    1.3784     0.23264\n",
      "   0.40811    0.09424    0.80493    1.189      0.3709     0.2923\n",
      "   0.051458  -0.91471    0.79913    0.031613   0.23426   -0.078071\n",
      "   0.55265   -0.094033  -0.067781   0.94492    0.13196   -0.2352\n",
      "   1.6138    -0.31953   -1.3038    -0.33394    1.0244     0.12196\n",
      "   1.5858     1.0825    -0.15639   -0.38267   -0.76347   -0.49954\n",
      "  -0.5254    -0.33106    0.29729   -0.17441   -0.076043  -0.83093\n",
      "  -0.47857   -0.029247  -0.26329   -0.3085     0.15287   -0.30547\n",
      "   0.15899   -0.30671  ]\n",
      " [ 0.53661   -0.33872    0.28772   -0.72584   -0.041209   0.28498\n",
      "   0.21665    0.62408   -0.1204     0.41135    0.10111   -0.11545\n",
      "  -0.15652   -0.39265    0.66286    0.71563    0.4214    -0.37041\n",
      "  -0.081016  -0.2901    -0.28407    0.30707    0.035974   0.32002\n",
      "   0.45456   -2.083     -0.6589    -0.081918   1.0431     0.50839\n",
      "   2.5433     0.81832   -0.11508   -1.1471    -1.0422    -0.22972\n",
      "  -0.68159   -1.3633     0.063994  -0.27115   -0.41006    0.090468\n",
      "   0.19801    0.486      0.84081    0.38655   -0.40763    0.20565\n",
      "  -0.1169    -0.55731  ]\n",
      " [-0.044806   0.24917    0.088818  -0.7982     0.15031    0.6785\n",
      "   0.83496    0.86424   -0.71302    0.75296   -0.31585   -0.2964\n",
      "  -0.12553   -0.73859    0.1535     0.18059   -0.080169   0.0029328\n",
      "  -0.14163   -0.56985    0.38888    0.6309     0.038375  -0.32777\n",
      "   0.72166   -1.9699     0.081391   0.55689    0.73193    0.83258\n",
      "   2.0362     1.1322     0.31967   -1.1327    -1.3813    -0.30716\n",
      "  -0.77535   -1.5439     0.02619   -0.067238   0.018815   0.47666\n",
      "  -0.80437    0.13336    1.0504     0.28345   -0.54026    0.3938\n",
      "  -0.3018    -0.91219  ]\n",
      " [ 0.38248    1.3166    -0.67796   -0.23382    0.92055    0.39705\n",
      "   1.0954     1.3475    -0.33678    0.71333    0.055274   0.25823\n",
      "  -0.14289   -0.72494    0.60271    0.048186  -0.55067   -0.0056619\n",
      "  -0.015116  -0.679     -0.52649    1.4572     0.44992   -0.70761\n",
      "   1.561     -0.41428   -1.1798     0.98563    1.0045     0.8048\n",
      "   1.1182     1.3909     0.70073   -0.49185   -0.9694    -0.32769\n",
      "  -0.34098   -1.3959     0.67482    0.13914    0.18353    0.25068\n",
      "  -0.92972   -0.28589    0.27042    0.84941   -0.44641    0.50314\n",
      "  -0.37851   -0.65623  ]\n",
      " [-0.55735    0.088292  -0.34505   -0.5124     0.33486    0.50618\n",
      "   0.90091    0.87638   -0.55048    0.3189    -0.14744   -0.022987\n",
      "  -0.32802   -0.22225    0.023042  -0.26524   -0.53355    0.013756\n",
      "  -0.098625  -0.88335   -0.018759   0.90394    0.2552    -0.48816\n",
      "   0.85611   -1.1937    -0.19683    1.0503     0.4081     0.23352\n",
      "   0.52848    1.1698     0.28227   -0.8829    -1.5182    -0.15557\n",
      "  -0.37392   -1.0123     0.38461   -0.21142    0.36867    0.26028\n",
      "  -0.9847     0.6882     0.38737    0.090635  -0.22709    0.25281\n",
      "   0.23433   -1.0114   ]\n",
      " [ 0.43138    0.2556    -0.0054598  0.2672     0.41846   -0.30282\n",
      "  -0.42898    1.2554    -0.37419    0.42207   -0.38164   -0.45101\n",
      "  -0.24843   -0.18889    0.85612   -0.15808    0.13082   -0.77788\n",
      "  -1.0247    -0.47486    0.054011  -0.1516    -0.18829   -0.36845\n",
      "   0.44512   -1.571     -0.55777    0.21816    0.26315    0.18359\n",
      "   2.0894     0.68849   -0.16336   -0.1216     0.038419  -0.302\n",
      "   0.06687    0.21847   -0.47899   -1.1706     0.093452   0.28611\n",
      "  -0.55597   -0.65429    0.66782    0.04971   -0.0052173  0.7006\n",
      "   0.32465    0.24523  ]\n",
      " [ 0.10193   -0.31175   -0.32207   -0.069121   0.83464   -0.19136\n",
      "   0.61143   -0.048183  -0.569     -0.31074    1.0109     0.41018\n",
      "   0.07679    0.53938   -0.35247    1.0868     0.87827   -0.15841\n",
      "  -0.28287   -0.71635   -0.050837  -0.024865   0.73021    0.60965\n",
      "  -0.748     -0.63331    0.59424    0.89076    0.21573    0.68681\n",
      "   2.047     -0.46433   -0.081564  -0.84879   -0.21514   -0.77163\n",
      "  -0.18683   -0.16663   -0.51517   -0.67673    0.46657   -0.33409\n",
      "   0.72181    0.15686   -0.52404   -0.22546   -0.23131    0.32637\n",
      "   0.30859    0.54118  ]\n",
      " [ 0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.       ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,inputSentence).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 7\n",
    "iterations = 100000\n",
    "maxSeqLength = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/idsMatrix.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ea30a64e6af8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/idsMatrix.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/idsMatrix.npy'"
     ]
    }
   ],
   "source": [
    "ids = np.load('Data/idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.load('Data/mergedLabel.npy')\n",
    "filteredtext = np.load('Data/filteredText.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randint\n",
    "\n",
    "# labels = []\n",
    "# batchSize =24\n",
    "# arr = np.zeros([batchSize, maxSeqLength])\n",
    "# for i in range(batchSize):\n",
    "#      num = randint(1,39999)\n",
    "#      print(num)\n",
    "#      labeltxt = label[num]\n",
    "#      print(labeltxt)\n",
    "#      labelemo = filteredtext[num]\n",
    "#      print(labelemo)\n",
    "#      labelindex = wordsList.index(labeltxt)\n",
    "#      print(labelindex)\n",
    "#      arr[i] = ids[num-1:num]\n",
    "#      print(arr[i].shape)\n",
    "#      if labeltxt==\"happiness\":\n",
    "#         labels.append([1,0,0,0,0,0,0])\n",
    "#      elif labeltxt==\"fear\":\n",
    "#         labels.append([0,1,0,0,0,0,0])\n",
    "#      elif labeltxt==\"anger\":\n",
    "#         labels.append([0,0,1,0,0,0,0])\n",
    "#      elif labeltxt==\"sadness\":\n",
    "#         labels.append([0,0,0,1,0,0,0])\n",
    "#      elif labeltxt==\"disgust\":\n",
    "#         labels.append([0,0,0,0,1,0,0])\n",
    "#      elif labeltxt==\"surprise\":\n",
    "#         labels.append([0,0,0,0,0,1,0])\n",
    "#      elif labeltxt==\"neutral\":\n",
    "#         labels.append([0,0,0,0,0,0,1])\n",
    "#      print(labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(10000,47515)\n",
    "        labeltxt = label[num]\n",
    "        labelindex = wordsList.index(labeltxt)\n",
    "        arr[i] = ids[num-1:num]\n",
    "        if labeltxt==\"happiness\":\n",
    "            labels.append([1,0,0,0,0,0,0])\n",
    "        elif labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0,0])\n",
    "        elif labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0,0])\n",
    "        elif labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0,0])\n",
    "        elif labeltxt==\"disgust\":\n",
    "            labels.append([0,0,0,0,1,0,0])\n",
    "        elif labeltxt==\"surprise\":\n",
    "            labels.append([0,0,0,0,0,1,0])\n",
    "        elif labeltxt==\"neutral\":\n",
    "            labels.append([0,0,0,0,0,0,1])\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,9999)\n",
    "        labeltxt = label[num]\n",
    "        labelindex = wordsList.index(labeltxt)\n",
    "        arr[i] = ids[num-1:num]\n",
    "        if labeltxt==\"happiness\":\n",
    "            labels.append([1,0,0,0,0,0,0])\n",
    "        elif labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0,0])\n",
    "        elif labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0,0])\n",
    "        elif labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0,0])\n",
    "        elif labeltxt==\"disgust\":\n",
    "            labels.append([0,0,0,0,1,0,0])\n",
    "        elif labeltxt==\"surprise\":\n",
    "            labels.append([0,0,0,0,0,1,0])\n",
    "        elif labeltxt==\"neutral\":\n",
    "            labels.append([0,0,0,0,0,0,1])\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(24), Dimension(80), Dimension(50)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-773132a4e1b5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#    #Next Batch of reviews\n",
    "#    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "#    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "#    #Write summary to Tensorboard\n",
    "#    if (i % 50 == 0):\n",
    "#        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "#        writer.add_summary(summary, i)\n",
    "\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"emoDetectModel/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't load save_path when it is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1deee1a39b7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#saver = tf.train.Saver()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'emoDetectModel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1680\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1683\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't load save_path when it is None."
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('emoDetectModel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 29.1666656733\n",
      "Accuracy for this batch: 25.0\n",
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 12.5\n",
      "Accuracy for this batch: 20.8333328366\n",
      "Accuracy for this batch: 16.6666671634\n",
      "Accuracy for this batch: 16.6666671634\n",
      "Accuracy for this batch: 25.0\n",
      "Accuracy for this batch: 20.8333328366\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"\\n\", \" \")\n",
    "    return re.sub(strip_special_chars, \" \", string.lower())\n",
    "\n",
    "labelPrediction = [\"happiness\",\"fear\",\"anger\",\"sadness\",\"surprise\",\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
    "    cleanedSentence = cleanSentences(sentence)\n",
    "    split = cleanedSentence.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        try:\n",
    "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unknown words\n",
    "    return sentenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"i love you\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiness'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "\n",
    "# print(\"happiness = \",predictedSentiment[0])\n",
    "# print(\"fear=\",predictedSentiment[1])\n",
    "# print(\"anger=\",predictedSentiment[2])\n",
    "# print(\"sadness=\",predictedSentiment[3])\n",
    "# print(\"disgust=\",predictedSentiment[4])\n",
    "# print(\"surprise=\",predictedSentiment[5])\n",
    "# print(\"neutral=\",predictedSentiment[6])\n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(predictedSentiment), key=operator.itemgetter(1))\n",
    "\n",
    "labelPrediction[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"stomach ache\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiness'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "\n",
    "# print(\"happiness = \",predictedSentiment[0])\n",
    "# print(\"fear=\",predictedSentiment[1])\n",
    "# print(\"anger=\",predictedSentiment[2])\n",
    "# print(\"sadness=\",predictedSentiment[3])\n",
    "# print(\"disgust=\",predictedSentiment[4])\n",
    "# print(\"surprise=\",predictedSentiment[5])\n",
    "# print(\"neutral=\",predictedSentiment[6])\n",
    "\n",
    "import operator\n",
    "index, value = max(enumerate(predictedSentiment), key=operator.itemgetter(1))\n",
    "\n",
    "labelPrediction[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
