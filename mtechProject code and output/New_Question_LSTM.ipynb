{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'everi time i imagin someon i love i could contact serious ill even death'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json as j\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import csv\n",
    "\n",
    "data = pd.read_csv('iseardataset.csv')\n",
    "test_data = data\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "data['cleaned'] = data['text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "test_data['cleaned'] = data['text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "data['cleaned'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.35215 , -0.35603 ,  0.25708 , -0.10611 , -0.20718 ,  0.63596 ,\n",
       "       -1.0129  , -0.45964 , -0.48749 , -0.080555,  0.43769 ,  0.46046 ,\n",
       "       -0.80943 , -0.23336 ,  0.46623 , -0.10866 , -0.1221  , -0.63544 ,\n",
       "       -0.73486 , -0.24848 ,  0.4317  ,  0.092264,  0.52033 , -0.46784 ,\n",
       "        0.016798, -1.5124  , -0.19986 , -0.43351 , -0.59247 ,  0.18088 ,\n",
       "        3.5194  , -0.7024  ,  0.23613 , -0.68514 , -0.37009 , -0.080451,\n",
       "        0.10635 , -0.085495, -0.18451 ,  0.29771 ,  0.18123 ,  0.53627 ,\n",
       "       -0.1001  , -0.55165 ,  0.098833, -0.12942 , -0.82628 , -0.4329  ,\n",
       "       -0.10301 , -0.56079 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "SeqLength = 42\n",
    "counter = 0\n",
    "for p in wordsList:\n",
    "    counter = counter+1\n",
    "    if counter >= SeqLength:                \n",
    "        break\n",
    "        \n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "wordVectors[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeltext = data['label']\n",
    "\n",
    "labeltext1= data['label']\n",
    "\n",
    "\n",
    "testdata = data['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueLabel=[]\n",
    "for w in labeltext:\n",
    "    if w not in uniqueLabel:\n",
    "        uniqueLabel.append(w)\n",
    "        \n",
    "uniqueLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7516"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter=[]\n",
    "for word in uniqueLabel:\n",
    "    count=0\n",
    "    for word1 in labeltext:\n",
    "        if word==word1:\n",
    "            count=count+1\n",
    "    counter.append(count)\n",
    "    \n",
    "sum(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on day i feel close partner friend when i feel peac also experi close contact peopl i regard great'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = data['cleaned']\n",
    "\n",
    "\n",
    "len(list1)\n",
    "\n",
    "\n",
    "list1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of files is 7516\n",
      "The total number of words in the files is 91532\n",
      "The average number of words in the files is 12.178286322511974\n"
     ]
    }
   ],
   "source": [
    "numWords=[]\n",
    "x = []\n",
    "for pf in list1:\n",
    "    counter = len(pf.split())\n",
    "    x.append(counter)\n",
    "    numWords.append(counter)\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "# fileCounter = 0\n",
    "# for pf in list1:\n",
    "#     indexCounter = 0\n",
    "#     cleanedLine = cleanSentences(pf)\n",
    "#     split = cleanedLine.split()\n",
    "#     for word in split:\n",
    "#         try:\n",
    "#             ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#         except ValueError:\n",
    "#             ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#         indexCounter = indexCounter + 1\n",
    "#         if indexCounter >= maxSeqLength:\n",
    "#             break\n",
    "#     fileCounter = fileCounter + 1 \n",
    "    \n",
    "# np.save('idsMatrixQ1', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "# fileCounter = 0\n",
    "# for pf in testdata:\n",
    "#     indexCounter = 0\n",
    "#     cleanedLine = cleanSentences(pf)\n",
    "#     split = cleanedLine.split()\n",
    "#     for word in split:\n",
    "#         try:\n",
    "#             ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#         except ValueError:\n",
    "#             ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#         indexCounter = indexCounter + 1\n",
    "#         if indexCounter >= maxSeqLength:\n",
    "#             break\n",
    "#     fileCounter = fileCounter + 1 \n",
    "    \n",
    "# np.save('idsMatrixQ2', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    61,     41,    998,   6710, 399999,     41,  90634,    530,\n",
       "           41,   2716, 399999,  86821,   1927,   1671,     79, 399999,\n",
       "        11056,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids1 = np.load('idsMatrixQ1.npy')\n",
    "\n",
    "\n",
    "ids1[41]\n",
    "\n",
    "\n",
    "ids = np.load('idsMatrixQ2.npy')\n",
    "ids[0]\n",
    "\n",
    "ids[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,7515)\n",
    "        labeltxt = labeltext[num]\n",
    "        if labeltxt==\"joy\":\n",
    "            labels.append([1,0,0,0,0,0,0])\n",
    "        if labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0,0])\n",
    "        if labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0,0])\n",
    "        if labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0,0])\n",
    "        if labeltxt==\"disgust\":\n",
    "            labels.append([0,0,0,0,1,0,0])\n",
    "        if labeltxt==\"shame\":\n",
    "            labels.append([0,0,0,0,0,1,0])\n",
    "        if labeltxt==\"guilt\":\n",
    "            labels.append([0,0,0,0,0,0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,7515)\n",
    "        labeltxt = labeltext1[num]\n",
    "        if labeltxt==\"joy\":\n",
    "            labels.append([1,0,0,0,0,0,0])\n",
    "        if labeltxt==\"fear\":\n",
    "            labels.append([0,1,0,0,0,0,0])\n",
    "        if labeltxt==\"anger\":\n",
    "            labels.append([0,0,1,0,0,0,0])\n",
    "        if labeltxt==\"sadness\":\n",
    "            labels.append([0,0,0,1,0,0,0])\n",
    "        if labeltxt==\"disgust\":\n",
    "            labels.append([0,0,0,0,1,0,0])\n",
    "        if labeltxt==\"shame\":\n",
    "            labels.append([0,0,0,0,0,1,0])\n",
    "        if labeltxt==\"guilt\":\n",
    "            labels.append([0,0,0,0,0,0,1])\n",
    "        arr[i] = ids1[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 64\n",
    "lstmUnits = 10\n",
    "numClasses = 7\n",
    "iterations = 100000\n",
    "numDimensions = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(24), Dimension(50)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(64, 7), dtype=float32)\n",
      "Tensor(\"Equal:0\", shape=(64,), dtype=bool)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-27-24b8ea197ad3>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "print(prediction)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "print(correctPred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "print(accuracy)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#    #Next Batch of reviews\n",
    "#    nextBatch, nextBatchLabels = getTrainBatch()\n",
    "#    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "#    #Write summary to Tensorboard\n",
    "#    if (i % 50 == 0):\n",
    "#        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "#        writer.add_summary(summary, i)\n",
    "\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"models1/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models1\\pretrained_lstm.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 60.9375\n",
      "Accuracy for this batch: 70.3125\n",
      "Accuracy for this batch: 46.875\n",
      "Accuracy for this batch: 54.6875\n",
      "Accuracy for this batch: 60.9375\n",
      "Accuracy for this batch: 57.8125\n",
      "Accuracy for this batch: 53.125\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 56.25\n",
      "Accuracy for this batch: 67.1875\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 56.25\n",
      "Accuracy for this batch: 56.25\n",
      "Accuracy for this batch: 54.6875\n",
      "Accuracy for this batch: 67.1875\n",
      "Accuracy for this batch: 70.3125\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 65.625\n",
      "Accuracy for this batch: 65.625\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 57.8125\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 57.8125\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 53.125\n",
      "Accuracy for this batch: 53.125\n",
      "Accuracy for this batch: 64.0625\n",
      "Accuracy for this batch: 51.5625\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 62.5\n",
      "Accuracy for this batch: 65.625\n",
      "Accuracy for this batch: 43.75\n",
      "Accuracy for this batch: 65.625\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 53.125\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 51.5625\n",
      "Accuracy for this batch: 59.375\n",
      "Accuracy for this batch: 57.8125\n",
      "Accuracy for this batch: 42.1875\n",
      "Accuracy for this batch: 64.0625\n",
      "Accuracy for this batch: 57.8125\n",
      "Accuracy for this batch: 54.6875\n",
      "Accuracy for this batch: 68.75\n",
      "Accuracy for this batch: 56.25\n",
      "Accuracy for this batch: 56.25\n"
     ]
    }
   ],
   "source": [
    "iterations = 50\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "def getSentenceMatrix(sentence):\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
    "    cleanedSentence = cleanSentences(sentence)\n",
    "    split = cleanedSentence.split()\n",
    "    for indexCounter,word in enumerate(split):\n",
    "        try:\n",
    "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unkown words\n",
    "    return sentenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"When I was not accepted as a student in finance and accounting.\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.8039901\n",
      "fear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.06949106,  1.8039901 , -0.872873  ,  0.00306439,  0.49031854,\n",
       "       -0.20453809, -0.3636682 ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "max1 = 0\n",
    "count = 0\n",
    "for i in range(0,6):\n",
    "    if predictedSentiment[max1] < predictedSentiment[i]:\n",
    "        max1 = i\n",
    "        count = predictedSentiment[i]\n",
    "\n",
    "print(max1,count)\n",
    "print(uniqueLabel[max1])\n",
    "predictedSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"When one lets friends down\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.57973254\n",
      "sadness\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.17515756, -0.5884043 , -0.58662677,  0.57973254,  0.43536714,\n",
       "        0.01479686, -0.09924237], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "max1 = 0\n",
    "count = 0\n",
    "for i in range(0,6):\n",
    "    if predictedSentiment[max1] < predictedSentiment[i]:\n",
    "        max1 = i\n",
    "        count = predictedSentiment[i]\n",
    "\n",
    "print(max1,count)\n",
    "print(uniqueLabel[max1])\n",
    "predictedSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"When the whole family gets together for a one week holiday.\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9272617\n",
      "fear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.60364896,  0.9272617 , -1.0228194 , -0.370823  ,  0.7914897 ,\n",
       "       -1.3466926 ,  0.191217  ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "max1 = 0\n",
    "count = 0\n",
    "for i in range(0,6):\n",
    "    if predictedSentiment[max1] < predictedSentiment[i]:\n",
    "        max1 = i\n",
    "        count = predictedSentiment[i]\n",
    "\n",
    "print(max1,count)\n",
    "print(uniqueLabel[max1])\n",
    "predictedSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText = \"On days when I feel close to my partner and other friends. When I feel at peace with myself and also experience a close contact with people whom I regard greatly.\"\n",
    "inputMatrix = getSentenceMatrix(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On days when I feel close to my partner and other friends.   \n",
      "When I feel at peace with myself and also experience a close  \n",
      "contact with people whom I regard greatly.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 80) for Tensor 'Placeholder_1:0', which has shape '(64, 24)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b2d053c72793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0minputMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetSentenceMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputText\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpredictedSentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputMatrix\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mmax1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1105\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (64, 80) for Tensor 'Placeholder_1:0', which has shape '(64, 24)'"
     ]
    }
   ],
   "source": [
    "inputArray = pd.read_csv('iseardataset.csv')\n",
    "inputTextArray = inputArray[\"text\"]\n",
    "inputLength = len(inputTextArray)\n",
    "i=0\n",
    "for text in inputTextArray:\n",
    "    inputText = text\n",
    "    print(text)\n",
    "    inputMatrix = getSentenceMatrix(inputText)\n",
    "    i=i+1\n",
    "    predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
    "    max1 = 0\n",
    "    count = 0\n",
    "    for j in range(0,6):\n",
    "        if predictedSentiment[max1] < predictedSentiment[j]:\n",
    "            max1 = j\n",
    "            count = predictedSentiment[j]\n",
    "    predictedArray[i] = uniqueLabel[max1]\n",
    "    if(i>=inputLength):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7516"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputTextArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports: \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2222222222222222, 0.3333333333333333, 0.26666666666666666, None)\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
    "y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
    "print(precision_recall_fscore_support(y_true, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
